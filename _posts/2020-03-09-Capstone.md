---
title: "Capston: 딥러닝 기반 수화 교육 어플리케이션"
excerpt: "딥러닝을 기반으로한 수화 학습용 어플리케이션"

categories:
  - Project
tags:
  - Deep Learning
last_modified_at: 2020-03-09T15:47:00
---
주제: 딥러닝을 이용한 수화 교육 어플리케이션  
제작 기간: 2019.09. - 2019.12.  
분류: 팀프로젝트

**동기**    
기존에 존재하는 수화 학습용 어플리케이션들은 단순하게 사전적인 정보만을 전달하여 학습시 보조적인 역할만이 가능하다는 점에서 아쉬움을 느꼈다.  
따라서 바쁜 사회에 어플리케이션만을 이용하여 능동적으로 학습할 수 있는 어플리케이션을 만들고자 했다.  
카메라 인식을 기반으로 사용자의 손동작이 올바른 동작인지에 대한 여부를 판단하고자 했고 효과적인 판단을 위해 딥러닝 기술을 사용했다.  

-------------  
**진행 과정**  
1. 디자인  
**안드로이드 스튜디오**에서 개발했으며, UI 경우 **어플리케이션 구성**에서 자세히 설명되어 있다.  
2. 초기 구현  
수화를 인식하기 위해서는 먼저 손을 검출하는 것이 중요하다고 생각했다.  
초기 구현시, 손을 인식하기 위한 방법으로 손의 끝점과 손가락 개수, 손바닥 중심점을 검출하는 방법을 사용했다.  
순서는 다음과 같다.  
1) 피부색을 이용하여 손 후보 영역을 검출  
2) 손바닥 중심점 검출  
3) 손가락 개수 및 손의 끝점 검출  
4) 여러 개의 손 검출  
OpenCV를 사용하여 진행했으며 결과적으로 카메라를 통해 실시간으로 손 영역을 인식할 수 있었다.  
![손 끝점을 이용한 손 영역 검출 이미지](https://yuksangeun.github.io/assets/images/capstone/capstone-finger.png){: .align-center}  
하지만 손 끝을 검출하는 방식만으로는 간단한 동작만 가능하고(ex. 숫자) 수화의 다양한 손동작을 구현하기가 어렵다는 판단이 들어 다른 방법을 모색했다.  
이후 찾은 방법이 **딥러닝**이다.  


3. 딥러닝  
	1. DataSet  
	수화 데이터셋을 찾기가 어려워 데이터셋을 직접 만들었고 총 100개의 단어를 만들었다.  
	각 수어당 300장의 training 사진, 90장의 test사진을 생성했다.  
	촬영시 hsv 색상 모델로 마스킹하여 손 영역만이 흰색부분으로 보이도록 만들어 dataset을 형성했다.  
![DataSet](https://yuksangeun.github.io/assets/images/capstone/capstone-picture.png){: .align-center}  
	2. CNN  
	이미지 처리에 적합한 **CNN모델**을 사용하였다.  
		구축  
			- 이미지에 대한 특징을 추출하기 위한 convolutional Layer를 3계층으로 구축 후 convolutional Layer 사이사이에 pooling layer를 넣어 주었다.  
			- 추출된 이미지 특징을 가지고 이후 기존 뉴럴 네트워크에 넣어 분류하였다.  
![cnn 네트워크 구축](https://yuksangeun.github.io/assets/images/capstone/capstone-cnn.png){: .align-center}  
		학습 결과  
			- Accuracy , Precision , Recall , F1 score  
![cnn 학습 결과1](https://yuksangeun.github.io/assets/images/capstone/capstone-result1.png){: .align-center}  
![cnn 학습 결과2](https://yuksangeun.github.io/assets/images/capstone/capstone-result2.png){: .align-center}   
	3. 어플리케이션 구조  
		- Keras: Tensorflow 위에서 작동할 수 있는 파이썬 기반의 신경망 라이브러리 오픈소스  
		- 파이썬에서 Keras를 이용하여 수화 학습모델을 구현 후 tensorflow lite 모델로 변환하여 안드로이드에 적용  
![app construction](https://yuksangeun.github.io/assets/images/capstone/capstone-app-construction.png){: .align-center}  

> CNN모델 이미지 출처  
> <https://bcho.tistory.com/1149> 

------------------  
**어플리케이션 구성**  
1. UI flow  
기능은 크게 1)학습, 2)번역 으로 나뉜다.  
	1) 학습 기능은 종류가 4가지 존재한다.  
		- 수화 검색  
		- 오늘의 학습: 하루 학습량이 정해져 있으며 설정된 커리큘럼에 맞춰서 학습이 진행된다.  
		- 카테고리 학습: 카테고리별 단어들이 나뉘어 있고 원하는 단어를 선택하여 학습 가능하다.  
		- 퀴즈: 학습 종류별 퀴즈가 가능하고 랜덤으로 퀴즈를 실행한다.  
	2) 번역 기능에서는 단어 수준으로 번역이 가능하며 카메라에 동작을 취하면 알맞는 단어를 보여준다.  
![ui flow](https://yuksangeun.github.io/assets/images/capstone/capstone-ui-flow.png){: .align-center}  

2. 메뉴별 시연  
시연 순서는  
1) 앱 초기 실행 -> 이름 설정 -> 오늘의 학습  
2) 카테고리 학습  
3) 퀴즈  
4) 번역  
순으로 시행된다.  

--------------  
**프로젝트 특징**  
1. 기대효과  
	* 수화의 언어적 가치 인식 향상 : 수화도 하나의 언어임에도 불구하고 사람들 사이에서 인식이 낮다.  
	* 금전적/시간적 여유가 없는 사람들이 시간/장소를 불문하고 학습 가능하다는 편리성을 제공한다.  
	* 카메라를 통해 동작을 직접 수행해 볼 수 있으므로 수화를 쉽게 익힐 수 있다.  
	* 동작을 직접 수행해 보고 확인할 수 있다는 점에서 능동적인 학습이 가능하다.  
2. 한계(보완점)  
	* 나라별 수어가 다르고 다양하여 여러 나라의 수어를 다루기 보다 한국 수어만을 가지고 진행하였다.  
	* 수화 데이터셋을 찾기가 어려웠으며 발견하더라도 영어 알파벳 정도에 그쳤다. 따라서 학습을 진행하는 과정에서 팀원들의 손동작을 촬영하여 진행했고 더 다양한 데이터셋을 모으지 못한게 아쉽다.  
	* 한 학기라는 짧은 시간에 진행을 하였고 팀원 모두 딥러닝을 공부하는 단계였기 때문에 동적인 수화를 처리하는 것에 한계가 있었다.  

> 참조  - 수화 자료(한국 수어 사전 홈페이지)  
> <http://sldict.korean.go.kr/front/main/main.do>

프로젝트: <https://github.com/YukSangeun/Capstone>
