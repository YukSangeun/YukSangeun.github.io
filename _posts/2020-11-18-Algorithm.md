---
title: "알고리즘 : 면접 질문 정리"
excerpt: ""

toc: true
toc_sticky: true
toc_label: "LIST"

categories:
  - Subject
tags:
  - Programming
last_modified_at: 2020-11-18

---



## 알고리즘

**정렬 알고리즘**

* in-place sort: 입력으로 주어진 데이터 이외에 추가 메모리 공간을 사용하지 않고 연산 수행이 가능한 정렬을 의미합니다.

버블소트: n개의 원소로 이루어진 배열을 정렬할 때, 서로 인접한 두 개의 데이터를 비교해가면서 정렬을 진행하는 방식입니다. 1회전 할 때마다 값이 큰 데이터 순서로 오른쪽에 배치되며 n개의 데이터에 대해 n번 반복합니다.

* 시간복잡도: O(n*n) (최선, 최악, 평균 모두 동일)
* 장점: 구현이 매우 간단, 소스코드가 직관적, inplace sorting, stable sort
* 단점: 시간복잡도가 모두 O(n*n)으로 비효율적, 정렬되어있지 않은 원소가 정렬시의 자리로 가기 위해 교환연산이 많이 발생

힙소트: 완전 이진 트리를 기본으로하는 힙 자료구조를 기반으로한 정렬방식입니다. 먼저 최대힙을 구성 후 루트의 가장 큰 값을 추출한 다음 마지막 요소를 루트에 이동시키고 힙의 사이즈를 1 감소시킵니다. 힙의 사이즈가 1보다 크면 다시 최대힙 구성후 추출작업을 반복합니다.

* 시간복잡도: O(n log n) (최선, 최악, 평균) = O(n) (초기 최대힙 정렬) + O(n log n) (최대값 제거, 최대힙 정렬)
* 장점: 가장 크거나 가장 작은 값 구할 때 / 최대 k만큼 떨어진 요소들 정렬할 때 (삽입정렬보다 더욱 개선된 결과 얻어낼 수 있음)
* unstable sort

머지소트: divde and conquer전략을 통해 배열을 정렬하는 알고리즘으로 요소를 잘개 쪼갠 후 다시 합병하는 과정에서 정렬해 나가는 알고리즘입니다.

* 퀵소트와 차이점: 안전정렬, 피벗을 통해 정렬 후 영역을 나누는 것과 달리 영역을 쪼개고 합치는 과정에서 정렬한다.
* 두 영역을 합병하는 함수가 포인트: 합병의 대상이 되는 두 영역이 각 영역에 대해 정렬되어 있기 때문에 순차적으로 비교하며 정렬하면 된다. (여기서 추가 메모리 사용하므로 - 두 영역을 복사하기 위해 - inplace 아님)
* 시간복잡도: O(n log n) (최선, 최악, 평균)
* 장점: 순차적 비교로 정렬을 진행하므로 LinkedList의 정렬이 필요할 때 사용하면 효율적이다. (linkedlist를 퀵정렬을 이용해 정렬할 경우 임의접근(pivot접근과 끝에서부터 비교시 말하는 것 같다)으로 접근 연산에서 비효율적 - 오버헤드 발생이 증가)

삽입정렬: 2번째 원소부터 시작하여 현재에서 왼쪽의 원소들과 비교하여 삽입할 위치를 지정한 후, 원소를 뒤로 옮기고 지정된 자리에 자료를 삽입하여 정렬하는 알고리즘입니다.

* 시간복잡도: O(n*n) (최악, 평균), O(n) (최선, 모두 정렬된 상태 배열)
* 장점: 단순, 대부분 원소가 이미 정렬된 경우 매우 효율적, inplace sorting, stable sort, 선택정렬과 삽입정렬보다 상대적 빠르다.
* 단점: 평균,최악 시간복잡도 비효율적, 배열의 길이가 길어질수록 비효율적

선택정렬: bubble 정렬과 유사한 알고리즘으로, 해당 순서에 원소를 넣을 위치가 이미 정해져있고, 어느 원소를 넣을지 선택하는 알고리즘입니다. (먼저 해당 자리를 선택하고 그자리에 오는 값을 찾는 것) 1회전할 때마다 주어진 영역에서 가장 최솟값을 찾아 앞에 값과 교체하므로 값이 작은순서로 앞에서부터 정렬이 이루어집니다. 

* 시간복잡도: O(n*n) (최선, 최악, 평균 모두 동일)
* 장점: 구현 간단, 졍렬을 위한 비교횟수는 많지만 bubble sort에 비해 실제 교환 횟수가 적기 때문에 많은 교환이 일어나야 하는 자료상태에서 비교적 효율적, in place sorting
* 단점: 시간복잡도가 o(n*n)으로 비효율적, unstable sort

퀵소트: divided and conquer 전략을 통해 주어진 배열을 정렬하는 알고리즘입니다.  배열의 원소들 중 랜덤으로 한 원소를 골라 pivot으로 설정을 한 뒤, pivot을 기준으로 왼쪽에는 pivot보다 작거나 같은 값을, 오른쪽에는 더 큰 값을 배치시킵니다. 이렇게 pivot을 기준으로 분할된 두 영역에 대해 재귀적으로 같은 과정을 반복하여 배열을 정렬합니다.

* 시간복잡도: O(n log n) (최선, 평균), O(n*n) (최악, pivot값이 배열 구간에서 항상 최대 or 최소일 경우)
* 장점:
  * 불필요한 데이터의 이동을 줄이고 먼 거리의 데이터를 교환할 뿐만 아니라, 한 번 결정된 피벗들이 추후 연산에서 제외되는 특성 때문에, 시간 복잡도가 O(n logn)을 가지는 다른 정렬 알고리즘과 비교해도 가장 빠르다.
  * in place sorting
* 단점: unstable, 정렬된 배열에 대해서는 quick sort의 불균형 분할에 의해 오히려 수행시간이 더 많이 걸린다.

radix sort(기수정렬): 데이터를 구성하는 기본 요소를 이용하여 정렬을 진행하는 방식입니다. 낮은 자리수부터 비교하여 정렬해 나가는 방식으로 다른 데이터와 비교연산을 수행하지 않기 때문에 비교 연산을 수행하는 정렬방식에 비해 매우 빠른 알고리즘입니다.

* 자리수별 값을 정렬하며 중간 결과를 저장할 bucket 공간이 필요합니다. 숫자형식의 데이터 경우 자릿수별 나올 수 있는 값의 범위가 0~9로 각 숫자에 해당하는 버킷 10개를 지정합니다. 그다음 다음과 같은 과정을 반복합니다.
* 1의 자리수를 보며 각각의 버킷에 알맞게 담아준 뒤 버킷에서 순차적으로 뺀다면 1의 자릿수에 맞게 정렬됩니다.
* 이후 10의 자리수 100의 자리수 ... 최대 자리수까지 같은 과정을 반복하게 된다면 최종적으로 정렬된 값이 완성됩니다.
* 시간복잡도: O(d*(n+b)) (d는 정렬할 자릴수, b는 버킷의 개수)
* 장점: 문자열, 정수 정렬이 가능하며 비교연산을 수행하지 않으므로 더빠른 수행시간을 가진다., stable sort
* 단점: 자릿수가 없는 것은 정렬할 수 없음. 중간결과를 저장하기 위해 bucket 공간이 필요함
* 낮은 자리수부터 정렬하는 이유? (MSD와 LSD를 비교하라는 질문)
  * MSD는 가장 큰 자리수부터 counting sort하는 것을 의미하고, LSD는 가장 낮은 자리수부터 counting sort하는 것을 의미
  * LSD의 경우 160000과 1을 비교할 때, digit의 개수만큼 따져야하는 단점이 있음. 그에 반해 MSD는 마지막 자리수까지 확인해 볼 필요없다.
  * LSD는 중간에 정렬결과를 알 수가 없다. 반면, MSD는 중간에 중요한 숫자를 알 수 있어 시간을 줄일 수 있다. 그러나, 정렬이 되어있는지 확인하는 과정이 필요하고, 더 많은 버켓을 사용해 메모리를 더 사용한다.
  * LSD는 알고리즘이 일관되지만 MSD는 일관되지 못하므로 구현의 편의성을 위해 LSD를 주로 사용한다.

**counting sort**: 각 숫자가 몇 번 등장했는지를 세어 정렬하는 알고리즘입니다.

* 먼저, 배열 값의 최대값 크기로 이루어진 counting배열에 해당 값이 몇번 등장하는지 개수를 저장해줍니다.
* counting 배열을 누적합으로 만들어줍니다. 이제 counting배열에 들어있는 값은 해당 인덱스를 값으로 하는 요소가 기존 배열에서 존재할 위치를 나타내게 됩니다.
* 기존 배열의 뒤에서부터 돌면서 해당하는 값의 인덱스에 값을 넣어줍니다.
* 사용: 정렬하는 숫자가 특정한 범위 내에 있을 때 사용
* 장점: O(n) 시간복잡도
* 단점: counting 배열의 크기가 가능한 값의 범위만큼 크게 잡아야 하므로 비효율적이다.





**sorting algorithm에서 stable하다는 것은 무엇을 의미하나요?**

stable하다는 것은 동일한 element가 있을 때 정렬 전의 순서와 정렬 후의 순서가 동일함을 보장하는 것입니다. 

**sorting algorithm이 가짓수가 많은데 그 이유가 무엇일 것 같나요?**

정렬 알고리즘의 가짓수가 많은 이유는 먼저, 정렬 알고리즘마다 예상되는 속도가 다르기 때문입니다. 두번째로 속도가 아닌 공간 복잡도 또한 고려대상이 될 수 있습니다. merge sort 경우 insertion sort나 seleciton sort에 비해 추가 메모리 공간을 사용합니다.

마지막으로 stable한지 안한지에 따라 사용되어야 할 정렬 알고리즘이 다를 수 있습니다.

**quick sort에 대해 설명해 줄 수 있나요?**

quick sort는 divide-and-conquer 전략을 이용해 정렬을 수행하는 정렬 알고리즘입니다. 그중에서도 partitioninig이라는 아이디어를 이용합니다.

partitioning이란 pivot element를 기준으로 왼쪽은 pivot보다 작거나 같은 것을 모아주고 오른쪽은 pivot보다 크거나 같은 것을 모아주는 것을 의미합니다.

이러한 partitioning을 재귀적으로 진행하다보면 정렬이 완료됩니다.



**divide and conquer**

문제를 작은 2개의 문제로 분리하고 각각을 해결한 다음, 결과를 모아서 원래의 문제를 해결하는 전략입니다.

**DP**

동적 계획법이란 복잡한 문제를 간단한 여러 개의 하위 문제로 나누어 푸는 방법을 말합니다. 두 가지 방식으로 구현이 되며 top down 방식과 bottom-up 방식이 존재합니다.

top down방식 경우 큰 문제를 여러개의 하위 문제를 나누고 하위 문제들을 결합하여 최종적으로 최적의 해를 구합니다. 같은 하위 문제를 가지는 경우가 존재하며 중복 계산을 방지하기 위해 계산 값을 메모리에 저장해 사용하는 memoization기법을 사용합니다. 이를 통해 문제 계산 속도를 향상합니다. 재귀를 이용하여 구현합니다.

bottom up 방식 경우 작은 문제부터 계산해 나가는 방식으로 for문을 사용해 상위 문제를 해결해나갑니다.

**Greedy**

그리디 알고리즘은 탐욕적 알고리즘으로 각 단계별 지금 당장 좋은 방법만을 선택하여 해결하는 방식입니다. 동적 계획법보다 수행시간이 훨씬 빠르기 때문에 우용하지만 많은 경우 최적해를 찾지 못하며 적용 가능 경우가 두가지로 제한됩니다.

* 탐욕법을 사용해도 항상 최적해를 구할 수 있는 경우
* 시간이나 공간적 제약을 최적해 대신 근사해를 찾아서 해결하는 경우

**재귀 알고리즘과 재귀의 시간 복잡도**

재귀 알고리즘이란 함수 내부에서 함수가 자기 자신을 또 다신 호출하여 문제를 해결하는 알고리즘 입니다. 재귀 알고리즘은 계속해서 자신을 호출함으로써 끝없이 반복하게 되므로 반복을 중단할 조건이 반드시 필요합니다.

팩토리얼을 계산하는 재귀함수에서는 T(n) = T(n-1) + c (n과 f(n-1)을 곱하는 비용)을 조회하고 점화식을 계산하면 아래와 같이 O(n)이 됨을 알 수 있습니다.

```
T(n) = T(n-1) + c
	= T(n-2) + 2c
	= T(n-3) + 3c
	= ...
	= T(1) + (n-1)c
	<= c + (n-1)c = cn = O(n)
```



**n개의 배열에서 k번째로 큰 수 찾는 알고리즘**

보통 퀵정렬 알고리즘을 사용하여 해결할 수 있습니다. 하지만 퀵정렬을 사용할 경우 정렬이 불필요한 부분들을 정렬하면서 효율적이지 못하게 됩니다. 때문에 부분만 정렬을 수행할 수 있도록 퀴선택 알고리즘을 사용합니다.

* 퀵선택 알고리즘이란 퀵정렬 후 피봇의 인덱스와 k를 비교해 아래와 같이 수행합니다.
* pivot의 인덱스 == k인 경우: 인덱스의 값 리턴
* pivot의 인덱스 < k인 경우: pivot의 인덱스 +1 부터 배열의 끝 인덱스까지 다시 partition함수에 넘겨준다.
* pivot의 인덱스 > k인 경우: pivot의 인덱스 -1 부터 배열의 처음 인덱스까지 partition함수에 넘겨준다.
* 시간 복잡도는 n + n/2 + n/4 + ... + 1 = O(n)

**허프만 코딩이란**

허프만 코딩은 문자의 빈도를 이용해 압축하는 방법으로 빈도가 높은 문자에 짧은 코드를 부여합니다. 허프만 코드는 접두부 코드와 최적 코드를 사용합니다.



