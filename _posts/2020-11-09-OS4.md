---
title: "운영체제 : 메모리 관리 체계"
excerpt: "주소바인딩? 메모리 관리 전략? 가상메모리?"

toc: true
toc_sticky: true
toc_label: "LIST"

categories:
  - Subject
tags:
  - Programming
last_modified_at: 2020-11-09

---

## 주소 바인딩

* 운영체제는 각 프로세스들이 메모리에 올라왔을 때, 다른 프로세스의 메모리 공간 접근을 막는다.
* 메모리에서 두개의 register를 이용해 프로세스들의 메모리 공간을 나눈다.
  * base reegister: 시작위치
  * limit register: 할당된 메모리 크기
* logical address: 프로그램이 컴파일 되어 메모리에 올라간 후, CPU에 의해 명령어가 한 문장씩 실행되게 되는데 CPU가 명령문을 실행함으로써 발생하는 메모리 주소. virtual address라고도 한다.
* physical address: 실제 접근해야하는 메모리 주소
* 주소 바인딩: 프로세스가 접근해야하는 변수와 함수에 대해 주소가 정해지는 것
* 주소 바인딩 시점에 따라 logical address와 physical address는 다를 수 있으며, 각 경우 해결방법에 대해 알아보자.
  * 컴파일 타임 바인딩
  * 로드 타임 바인딩
  * 실행 시간 바인딩



**컴파일 타임 바인딩**

컴파일 작업 중(실행파일 만들 떄) 명령어들과 변수의 물리적 메모리 주소가 결정되는 주소 바인딩이다. 프로그램의 물리적 주소를 변경하고 싶을 경우 다시 컴파일 해야 한다.

logical address와 physical address가 같다.

* <span style="color:red">**문제점**</span>? 컴파일 시점에 주소가 결정되면 각 변수와 메모리의 주소가 초기 지정되는 것이므로, 프로그램을 다른 시스템에서 실행하였을 때 해당 시스템의 메모리를 어디서부터 할당해주는지를 나타내는 Starting Point가 다르거나 이미 그 주소에 다른 프로그램이 실행 중이라면 이 프로그램은 실행할 수 없게 된다. (컴파일을 통해 해당 프로그램이 몇 번지에 올라가서 수행될지가 결정된다.)
* **가능한 상황**? 아두이노와 같이 내가 만든 프로그램 이외에 다른 프로그램이 안들어갈 경우(한 프로그램밖에 안돌아가므로 주소가 겹칠일이 없다.) **OS도 없고 프로세스가 딱 하나 있을 때 사용할 수 있는 방법**, <span style="color:blue">**임베디드 시스템**</span>에서 사용하는 방법이다. 현재 멀티프로그래밍 시스템에서는 불가능!



**로드 타임 바인딩**

프로그램이 컴파일 되고, 메모리에 올라갈 때 CPU에서 주소계산이 일어난 후 발생하는 주소. 즉, 프로그램의 실행이 시작될 때 물리적 주소가 결정된다. 이때 주소가 부여된 프로그램은 종료될 때까지 물리주소가 고정된다.

컴파일 된 프로그램 내부에서 사용하는 주소는 프로그램 내부의 메모리 시작을 0번지부터 해서 **상대 주소**를 쓴다. 이를 통해, 프로그램이 올라간 메모리의 base register 값에 상대 주소를 더하여 주소를 만들어 낸다.

물리적 주소와 논리적 주소가 동일하다.

* <span style="color:red">문제점</span>? 프로그램 안에서 사용하는 주소와 physical memory에서 사용하는 주소를 분리했으므로 이 프로그램은 physical memory 어디에서나 loading되어 수행 가능하다. 즉, multiprogrammnig이 가능!
* 하지만, 메모리에 참조하는 수많은 명령어들에 대해 바꿔주는 작업을 수행해야 하므로 **메모리 로딩시 시간이 엄청 오래 걸린다**(overhead가 크다). 실제로 안쓰이고 있다.



**실행 시간 바인딩(run time binding)**

프로그램이 실행한 후에도 물리적 주소가 변경될 수 있는 바인딩 방식이다. (매번 명령어가 실행될 떄마다 주소가 계산된다.)

CPU가 주소를 참조할 때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지 **주소 매핑 테이블**을 이용해 주소 바인딩을 점검한다. 이를 위해 **base register, limit register, MMU(Memoty Management Unit)**이 필요하다.

런타임 바인딩은 주소공간이 연속적으로 적재되어 있음을 가정한다.

* **MMU**:  **논리적 주소를 물리적 주소로 매핑해주는 하드웨어**,  CPU가 프로세스의 작업을 수행하기 위해 프로세스의 논리적 주소를 참조하게 된다. 논리적 주소만으로 실제 메모리의 주소를 알 수 없기 때문에 논리 주소를 물리적 메모리로 연결시키는 작업이 필요하며, 이러한 연결작업을 말한다



## 메모리 관리

프로그램은 **메모리에 올리는 로드과정**과 **라이브러리 파일과 연결해주는 링킹 과정**을 통해 최종적으로 메모리에 올라가게 된다.

올라가서도 지속적으로 메모리 공간을 차지하는 것이 아니라 운영체제의 필요에 의해 swap-in 되거나 swap-out 되기도 한다. 이러한 과정들이 어떤 작업이며 어떻게 변화해 왔는지 알아보자.



**Dynamic Loading**

* 한정적인 메모리 공간으로 인해 생겨난 방법
* 메모리 공간이 한정되어 있고 그 공간의 크기가 그렇게 크지 않을 때 프로세스의 모든 모듈들을 올리기에는 공간이 부족하여 **모듈이 필요하면 그떄그때 올려주는 방법**이 Dynamic Loading
* 이 방법을 사용하게 되면 이용되지 않는 모듈은 메모리 공간에 올라가지 않기 때문에 그만큼의 메모리 공간을 절약할 수 있게 된다.
* 하지만 <span style="color:red">현재는 **가상 메모리 기법**을 사용하여 메모리 공간이 충분히 많다고 가정을 하고 로드를 하기 때문에 이 방법은 사용되지 않고 있다.</span>

**Dynamic Linking**

* 기존 링크: 라이브러리 파일을 서로 다른 프로그램이 사용할 때 매번 프로세스 메모리 공간에 해당 라이브러리를 확보하여 프로세스에 함께 올렸다. --> 같은 라이브러리 파일이 메모리 공간에 여러 번 올라감으로 메모리 공간의 낭비로 이어지게 된다.
* 실행되지 전까지는 링킹이 되지 않고, **실행이 될 때 특정 라이브러리 파일이 최초로 한 번 메모리에 올리고** 이 라이브러리를 사용하는 프로세스들은 라이브러리의 위치를 가리키는 **stub** 포인트를 갖게 되어 라이브러리를 참조한다. --> 중복으로 메모리에 올라가는 것을 막아 메모리 낭비를 막는다.

**Swapping** >> 중기 스케쥴링

우선순위가 높거나 중요한 프로세스가 메모리에 올라가려 할 때 공간이 부족하면 현재 메모리 위에 올라가 있는 프로세스 중 수많은 알고리즘 중 하나를 이용해 어떤 프로세스를 잠시 디스크에 저장하고 우선순위 높은 프로세스를 먼저 수행한다.

* 이 프로세스가 작업을 마치면 디스크에 있던 프로세스를 다시 메모리에 올리게 된다.
* 우선순위가 높거나 중요한 프로세스가 중간에 들어가는 것을 **swap-in**이라 하며, 자리를 내어주어 디스크로 빠지게 된느 과정을 **swap-out**이라고 한다.
* swap-out된 프로세스가 다시 메모리에 올라갈 때는 원래 있던 자리로 돌아가지 않을 수 있다.
* 발생 이슈: 
  * 수많은 알고리즘 중 상황에 맞는 알고리즘을 고르는 것
  * 디스크와 메모리 간의 속도 차로 인해 발생하는 이슈



## 메모리 관리 전략

효율적인 기억장치 운용을 위해서는 프로그램이나 데이터를 **언제** 주기억장치로 반입하고, **어디에** 배치하며, 완료된 작업의 프로그램이나 데이터는 **어떻게 제거**할 것인가를 결정하는 관리가 필요하다.



기억장치 관리 정책은 3가지 전략이 존재하다. **반입전략, 배치전략, 교체전략**

**반입전략(Fetch Strategic)**

프로그램이나 데이터를 주기억장치에 **언제 적재**할 것인지를 결정하는 전략

1. 요구 반입(Demand): 프로그램이나 데이터의 참조가 요구될 때만 적재 > **demand paging**
2. 예상 반입(anticipatory): 요구될 가능성이 큰 프로그램이나 데이터를 예상해서 적재하며, 명령어와 데이터가 메모리에 적재되는 과정

**배치전략(Placement Strategic)**

반입되는 프로그램이나 데이터. 즉, 입력되는 작업을 주기억장치의 어디에 위치(할당)시킬 것인지 결정하는 전략

* 메모리 할당 단위는 Byte 단위가 아니라 시스템의 block 단위이다.
* 2가지 할당 방식이 존재

1. 연속할당(Continuous Memory Allocation): 연속된 공간의 메모리를 프로세스에 할당해 주는 방법

   * 최초 적합(first-fit): 가용공간 중에서 첫 번째 분할 영역에 배치
   * 최적 적합(best-fit): 가용공간 중에서 배치 후 남는 공간, 단편화가 가장 적은 곳에 배치
   * 최악 적합(worst-fit): 가용공간 중에서 배치 후 남는 공간, 단편화가 가장 큰 곳에 배치
   * 최초적합과 최적적합이 speed와 storage untilization면에서 최악보다 더 낫다.

   **단편화**: 기억장치 공간에서 프로그램이나 작업에 할당할 수 없는 조각난 공간, 시스템의 block단위로 할당하다 보니 메모리 낭비가 일어난다.

   * 내부 단편화: 분할된 영역에 프로그램이나 작업이 할당된 후 남는 기억공간
   * 외부 단편화: 분할된 영역이 작아 프로그램이나 작업을 할당받지 못하는 기억공간

   **외부 단편화 해결방법**

   * 압축(compaction): 할당된 메모리 공간들을 한쪽으로 모아 연속된 공간을 확보하는 것. 실행시간에 주소 바인딩이 일어나는 프로그램들만 가능
   * 통합(coalescing): 기억장치 내에 인접되어 있는 단편화 공간을 하나의 공간으로 합치는 것

2. 비연속할당: 가상메모리를 활용 (가상메모리는 보조기억장치에 있음, 실제메모리가 주기억장치)

   * <span style="color:blue">**페이징(paging)**</span>: 프로그램 공간인 logical memeory는 page라는 일정한 크기의 블록, physical memory는 frame이라는 블록으로 분할한 후 **page table**을 이용하여 페이지의 **logical address**와 프레임의 **physical address**를 매칭시켜 관리하는 방법

     page크기와 frame크기는 같으며, page table의 인덱스 수는 page수와 같다.

     외부단편화는 없지만, **내부단편화**는 생길 수 있다.

     page table역시 메모리에 올라가 있으며, 잘못된 주소 접근을 방지하기 위해 PTBR(Page Table Base Register)와 PTLR(Page Table Length Register) 두 값을 사용한다.

   * <span style="color:red">페이징의 문제점1</span>: page table이 메모리에 올라가 있기 때문에 데이터나 명령문에 접근하기 위해서는 두 번의 메모리 access가 발생(페이지 테이블 한번, 실제 메모리 한번) > 비효율적 > 이를 위해 **TLB(Translation-Look aside Buffer)**방법을 사용

   * **TLB**: 일종의 캐시 역할을 하는 레지스터로 메모리에 여러 번 접근하는 것을 막기 위해 page table의 내용을 TLB에 저장하여 바로 메모리 접근이 가능하도록 한다. TLB에 존재하지 않을 경우 page table 접근.

   * <span style="color:red">페이징의 문제점2</span>: 내부단편화 발생 가능 > **valid-invalid bit**사용한 문제 해결

   * **valid-invalid bit**: page table에 valid-invalid bit 컬럼 생성. 현재 프로세서에 상용되고 있는 page 경우 v로 표시(접근 허용), 사용되고 있지 않으면 i로 표시(접근 불가)

   * <span style="color:red">페이징의 문제점2</span>: 공통의 코드를 갖는 여러 프로세스들이 page table을 가질 때 중복의 문제 발생 > 하나의 공통된 코드 부분 page만 메모리에 올려 공유

   * **페이지 테이블의 구조**: 계층적 구조, hashed page table, inverted page table(역전 구조, 전체적으로 하나의 테이블 가짐)

   * <span style="color:blue">**세크멘테이션(segmentation)**</span>: 가상 메모리를 서로 크기가 다른 논리적 구조 단위인 세그먼트(segment) 단위로 분할해서 메모리에 할당해 실제 메모리 주소로 변환하는 방법

   * segment의 예: main program, function, method, object, stack, symbol table, local variables

   * 각 세그먼트는 고유한 이름(번호)과 길이를 가지며, 주소변환을 위해 **segment table**을 사용한다. **세그먼트 번호(s), 한계주소(크기)(limit), 기준 주소**로 구성된다. (페이징과 다른점. 가변 크기)

   * 변위(d)가 한계주소크기(limt)을 초과하는지 검사를 통해 잘못된 주소 접근을 막는다.

   * **내부 단편화는 없지만, 외부 단편화 발생**

3. memory pool (메모리 풀): 단편화 문제 해결 방법(paging, sementation, memory pool)중 한가지 방법

   * 필요한 메모리 공간을 사용자가 직접 지정하여 **미리 할당받아 놓고 필요할 때마다 사용하고 반납**하는 기법
   * 미리 공간을 할당해놓고 사용하고 반납 > 외부 단편화 해결
   * 필요한 크기만큼 할당 > 내부 단편화 해결
   * it (단편화로 인한 낭비량 < pool을 만들었지만 사용하지 않을 때 누수양) 오히려 낭비
   * **메모리 할당, 해제가 잦은 경우 효과적**인 방법
   * 미리 할당하기 때문에 **메모리 누수**가 존재

**교채전략(Replacement Strategic)**

새로 반입되는 작업에 필요한 기억장소를 확보하기 위해 적재된 어떤 프로그램가 교체할 것인가를 결정하는 전략 > **Page Replacement** (뒤에서 배움)



## Virtual Memory

위에서 메모리 관리 기법(요구반입, 예상반입), 배치(연속, 비연속), 교체가 무엇인지에 대해 배웠다.

특히, 배치 기법 중 가상 메모리를 활영해 메모리 비연속 할당에 대해(paging, segmentation)에 대해 배웠는데 **가상메모리가 무엇인지, 가상메모리에서 paging 사용법**에 대해 자세히 알아보자.



**Virtual Memory**? 한정된 Physical memeory의 한계를 극복하고자 디스크와 같은 보조기억장치를 활용해 더 많은 메모리를 활용할 수 있게 하는 것.

**Demand Paging**? **swapping + paging**으로 실제로 필요한 page만 물리 메모리로 가져오는 방식

* physical memeory의 여유공간이 얼마나 되는지 고민할 필요 없다.
* 프로그램 전체가 메모리에 올라오는 것이 아니므로, 동시에 많은 프로그램을 메모리에 올려 작업 가능
* 한꺼번에 올라오는 소스의 양이 적어 disk와 memory간 I/O작업속도가 빨라진다.

* 가상 메모리에서 paging기법을 사용할 때 정확하게 demand paging기법으로 구현된다.

1. Valid-Invalid bit 사용

   * if **Bit == Valid** then **해당 Page Table의 인덱스 접근이 가능 + 실제 메모리에 올라와 있음**
   * if **Bit == Invalid** then **해당 Page Table의 인덱스는 접근 불가능 or 현재 Disk에 존재**
   * page fault: page 접근 요청을 했는데 physical memory에 없는 상태로 bit가 invalid인 상태를 의미

2. Page Fault: 지금 실행시켜야 할 page가 실제 메모리에 올라와 있지 않은 상태로 CPU의 자원 효율성을 떨어트리는 현상이다.

   * 자원 할당받은 시간내에 CPU자원을 사용하기 보다는 I/O작업에 시간 소비
   * 해결법?

   ```
   step1) Page Fault 발생하면 CPU는 운영체제에게 trap을 전송, 운영체제는 잠시동안 CPU의 작업을 멈춤
   step2) 운영체제가 disk에서 해당 부분을 찾아 실제 메모리의 비어 있는 frame에 올리고, page table의 해당 부분의 bit를 valid로 갱신한다.
   step2-1) 비어 있는 frame이 없을 경우 page replacement 알고리즘을 사용해 교체할 페이지를 지정하고 frame table과 page table을 갱신한다.
   step3) page fault를 발생시킨 명령어를 다시 실행하여 작업을 재개한다.
   ```

3. Page Replacement: 요구된 페이지가 반입할 공간(frame)을 확보하기 위해 교체될 페이지(victim page)를 선택하는 알고리즘 (page fault 해결 과정에서 사용된다)

   * Page replacement의 범위
     * global replacement: victim page를 찾을 때 모든 프로세스의 모든 페이지에서 찾음
     * local replacement: victim page를 찾을 대 해당 프로세스 내에서만 찾음
   * 알고리즘 종류: FIFO, OPT, LRU, NUR, SCR, 
   * **FIFO**: 실제 메모리에 가장 먼저 들어온 페이지를 교체하는 방법 / 이해가 쉽고 설계가 간편하지만 자주 사용 중인 페이지가 오래되었다는 이유만으로 교환되는 경우 불합리가 생김
     * 벨라디(Belady)모순 생김: 프레임이 증가될수록 페이지 부재율이 감소되어야 하는데 오히려 페이지 부재율이 증가되는 현상
   * **OPT(Optimal)**: 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체하는 방법 / 페이지 부재율이 가장 적은 최적의 방법이지만 예측하기 힘들다.
   * **LRU(Least Recently Used)**: 현 시점에서 가장 오랫동안 사용되지 않은 페이지를 제거하는 방법 / 참조된 시간을 기록하기 위해 계수기(counter)나 스택(stack)을 두어야 하므로 시간 오버헤드가 발생하고, 실제 구현은 복잡하다.
   * **NUR(Not Used Recently)**: LRU와 비슷한 알고리즘이지만, LRU의 단점인 시간 오버헤드를 적게 받는 방법 / 2개의 bit(참조 비트, 변형 비트)를 이용해 최근에 사용되지 않은 페이지를 교체하는 방법

   ```
   (참조, 변형)
   1. (0, 0) : 최근에 사용되지도 않고 변경되지도 않은 경우 - 교체되기 좋은 page
   2. (0, 1) : 최근에 사용되지 않고 변경만 된 경우
   3. (1, 0) : 최근에 사용은 되었으나 변경되지 않은 경우
   4. (1, 1) : 최근에 사용되었고 변경도 된 경우
   
   교체 우선순위: 1 > 2 > 3 > 4
   ```

   * **SCR(Second Chance Replacement)**: FIFO 교체 알고리즘을 기반으로 하는 알고리즘 / 페이지들을 circular queue 형태로 나타낸다. 1개의 bit(참조 비트)를 이용해, 페이지의 참조비트가 0이면 교체하고 1이면 0으로 바꾼 후 피드백 시켜 다시 한번 더 기회를 준 후 다음에도 0이면 교체한다.
   * <span style = "color:blue">**Thrashing**</span>: 페이지 부재가 자주 발생하여 페이지 교체가 빈번하게 일어나는 현상

   ```markdown
   * 원인? 
   가상 메모리를 사용하다 보면 실제 물리 메모리 공간보다 논리적 메모리 공간이 큰 것처럼 사용할 수 있어서 효율적이다. 효율적이라는 이유로 점점 많은 프로세스를 동시에 메모리에 올린다면, 하나의 프로세스가 할당 받는 자원의 양은 점점 작아지고 곧 할당 받는 frame의 수도 적어진다.
   Frame의 수가 적어지면 그만큼 Fage fault가 많이 발생하고, page replacement가 증가하면서 자원의 활용보다는 I/O작업에 시간을 더욱 쏟는 단점이 발생하며 CPU의 효율성 역시 굉장히 떨어진다.
   
   * mult-programming?
   CPU 자원의 효율성을 높이기 위해 보다 많은 프로세스에게 CPU를 할당해주면서 자원을 더욱 바쁘게 효율적으로 관리하는 기법
   
   * 예방법?
   각 프로세스들에게 충분한 page frame을 할당해준다.
   다중 프로그래밍의 정도를 줄인다.
   
   * 필요한만큼의 page frame의 수를 예측하는 방법?
   locality(지역성)을 근거로 둔 working set을 통해서 예측한다.
   
   **locality**: 프로세스가 실행되는 동안 기억장치 내의 모든 정보를 균일하게 참조하는 것이 아니라 현재 실행되는 주소 부근에서 집중적으로 참조한다는 특성
   **working set**: 실행 중인 프로세스가 일정 시간 동안에 참조한는 페이지들의 집합으로 지역성에 기반한 모델
   
   working set의 크기가 실제 메모리보다 커지면 하나의 프로세스를 종료하는 방법으로 thrashing 예방
   ```

4. Allocation of Frames (프레임 할당)

   * Fixed allocation: 
     * Equal allocation: 프로세스 목적과 성격에 상관없이 모든 프로세스에게 고정된 양의 frame할당
     * Proportional allocation: 프로세스의 사이즈에 비례하여 frame할당
   * Priority allocation: 우선순위가 높은 프로세스에게 더 많은 양의 frame할당 (page fault 횟수는 감소하게 되고, 프로세스는 작업을 빨리 마침)

5. Performance of Demand Paging (성능계산으로 ...생략)



## 가상 메모리의 부가 장점

1. **공유메모리 사용**
   * 여러 프로세스 간의 communication의 한 가지 방법으로 공유 메모리를 사용할 수 있는데,
   * demand-paging 기법을 사용할 경우 다른 프로세스의 각각의 페이지가 같은 프레임을 가리키도록 하면 공유메모리를 사용할 수 있다.
2. **copy-on-write** 메커니즘
   * 부모 프로세스를 clone하여 자식 프로세스를 생성하였을 때,
   * 처음에는 같은 메모리를 사용하도록 하다가 그곳에 write가 발생하였을 때 메모리를 copy하는 것으로 이것 또한 공유 메모리처럼 같은 프레임을 가리키도록 하였다가 복사가 되었을 때 새로운 프레임을 할당하면 된다.
3. **Memory mapped file**
   * file을 접근하는 것을 메모리 접근하듯이 페이지를 할당하여 할 수 있도록 하는 것이며,
   * 메모리 접근 속도가 훨씬 더 빠르므로 효율적이라고 할 수 있다.
   * (file은 disk에 저장되어 있음. disk접근 속도는 주기억장치 접근 속도보다 느리다)

