**임베디드 소프트웨어 프로젝트**

프로젝트 소개 (뭘 만든거고, 뭘 쓰고, 뭘 활용했고)

임베디드 소프트웨어 과목에서 진행한 프로젝트는 atmega128임베디드 보드를 애용해 타이머 제작 프로젝트 입니다. 

switch를 이용해 시간 설정과 알람 음계를 설정한 후 타이머를 작동하여 0초가 된다면 설정한 음계로 buzzer가 울리도록 구현했습니다. 구현 과정에서 LED, FND, Switch, Buzzer 장치를 활용했으며, C언어로 개발했습니다.

이를 위해 각 장치에 해당하는 task와 switch, buzzer를 제어하기 위한 인터럽트 서비스 루틴을 적절히 만들고 task간 통신기법을 적절히 활용함으로써 타이머를 제작했습니다.



어려웠던 점 , 해결과정

가장 어려웠던 점은 여러 task의 우선순위를 결정하고 태스크간 통신 방법을 설정하는 것이었습니다. 타이머라는 시스템이 원활하게 수행되기 위해서는 task들 중 무한대기하는 task가 없도록 우선순위를 결정하고 원활한 통신이 진행되도록 구현하는 것이 중요했습니다.

여러 task의 작업과정을 모두 생각하며 구현해야 했기 때문에 머리가 복잡했다.

이를 위해 각 task별 작업내용을 정리하고 타이머 수행시 task간 수행 순서를 도식화하여 정리했습니다. 정리한 내용을 보며 소외되는 task가 없도록 우선순위를 설정할 수 있었고 각 부분별 사용할 통신기법을 지정할 수 있었습니다.



배운점

해당 과목을 통해 임베디드 시스템에서의 멀티태스킹과 태스크간 통신기법 사용에 대해 알 수 있었습니다. 또한, 실시간 시스템에 대해 배울 수 있었습니다.

프로젝트를 통해 배운 점은 수업에서 배운 멀티태스킹과 통신기법들에 대해 실제 적용해 볼 수 있었으며, 복잡한 시스템을 구현하기 위해서는 초기 설계과정이 중요함을 알게됐습니다.



**캡스톤 프로젝트**

프로젝트 소개 (무엇을 만들고, 뭘 쓰고, 뭘 활용했는지)

제가 진행한 프로젝트는 카메라 기반에 딥러닝을 활용한 수화 학습 애플리케이션입니다.  학습할 수화 단어에 대해 사용자가 카메라 앞에서 손동작을 수행하고 맞는 동작인지 확인하며 능동적 수화 학습이 가능하도록 구현하는 것이 목표였습니다.

구현을 위해 안드로이드, 딥러닝, DB를 이용했으며, sql, 자바, 파이썬을 이용해 개발을 진행했습니다.

(프로젝트에서 저는 안드로이드 UI작업과 카메라를 연동하고 딥러닝 학습모델을 적용하는 업무를 맡았습니다) 

팀원들과 협업으로 93% 정확도를 가진 학습모델을 개발하여 수업에서 A0 성적을 받았습니다.



내가 담당했던 역할

저는 프로젝트에서 안드로이드 UI작업과 카메라 연동 후 딥러닝 학습모델을 안드로이드에 적용하는 업무를 맡았습니다.



구현했던 기술

딥러닝 - 수화 데이터를 어떤 방식으로 적용시켰는지?

-> 파이썬 기반의 신경망 라이브러리 오픈소스인 keras를 이용해 학습모델을 구현했으며, 구현시 이미지 처리에 적합한 CNN모델을 사용했습니다. 이미지에 대한 특징을 추출하기 위해 convolutional layer를 3계층으로 구축 후 계층 사이사이에 pooling layer를 넣어 오버핏 발생을 막았습니다. 또한, 추출된 특징을 가지고 기존 뉴럴 네트워크에 넣어 분류햇습니다. 이후 학습모델을 tensorflow lite모델로 변환해 안드로이드에 적용했습니다.

사지 저장 - hsv 색상 모델로 마스킹하여 손영역만 흰색부분으로 보이도록 설정했습니다. hsv 색상모델을 사용한 이유는 hsv색상모델 경우 명도, 채도, 색감을 세밀하게 조정할 수 있기때문에 다양한 환경에서 손영역을 확실하게 구분하기 더 적합하다고 생각했습니다.



어려웠던 점, 해결과정

2가지의 어려움이 존재했습니다.

먼저 딥러닝시 필요한 수화 학습 데이터 셋이 존재하지 않는다는 점

-> 국립국어원 한국 수어사전 홈페이지에서 수화 단어들을 선정 후 팀원들과 함께 촬영을 통해 각 수어당 300개의 training set과 90장의 test set을 생성했으며 총 100개의 수화단어에 대해 진행했다.

촬영시 hsv 색상 모델로 마스킹하여 손 영역만 흰색부분으로 보이도록 만들어 dataset을 형성함

두번째로 openCV관련해서 전면 카메라 연동 시 90도 회전되는 문제가 발생한다는 점

-> openCV 라이브러리 속 모든 class를 직접 확인했고 화면 관련 함수를 찾아 문제를 해결할 수 있었다.



배운점

협업하며 프로그램 제작하는 경험을 쌓을 수 있었고, 여러 언어를 사용해볼 수 있는 경험이었다. 또한 딥러닝과 같은 새로운 기술에 대해 짧지만 배울 수 있었다.



아쉬운 점

수화의 경우 정적인 동작 뿐만 아니라 동적인 동작도 존재하는데 동적인 동작을 처리하기 위해서는 더 고난이도의 딥러닝 기술을 필요했으며, 당시 우리의 기술력으로는 부족했다.

다양한 수화 동작에 대한 데이터셋이 존재하지 않아 많은 수화를 할 수 없었다는 점

얼굴 부분?



다른 부분에 카메라 앞에서 동작 수행하는 기능을 사용한다면 어디에 사용할지? 



창의적?

1. 영어 학습의 경우 직접 말하여 올바른 발음인지 확인하며 능동적 학습이 가능하다. 수화 또한 참고용 애플리케이션 벗어나 능동적 학습을 할 수 있도록 구현하고자 했다. 영어를 공부하기 위해서는 직접 말하며 공부하면 되듯이 수화를 학습하기 위해서는 동작을 수행하며 하면 된다고 생각했다. 이를 어플에서 확인해주면 좋을 것이라 생각해 카메라를 통한 학습을 생각해 냈다.

2. 바쁜 현대인에게 수화를 학원에서 배우기에 시간적 여유가 존재하지 않다. 그렇다면 일상생활에서 학원에 가는 것 없이 학원에서 하는 것처럼 배울 수 있게 하자. 학원에서 하는 것처럼 하기위해서는 선생님이 동작이 맞는지 확인해주듯 내동작을 확인해줄 것이 필요하다. 그럼 카메라를 이용해 개발하자!

왜 수화인가?

영어 회화를 배우기 위해 학원을 다닌적이 있습니다. 당시 사회복지사를 직업으로 가진 분이 존재했고 이분을 통해 짧지만 몇가지 수화를 배울 수 있었다. 수화를 배우는 것에 흥미를 느껴 수화 어플리케이션을 찾던 중 참고용 애플리케이션밖에 존재하지 않는다는 것을 느꼈고 좀 더 능동적인 학습을 위한 애플리케이션이 있으면 좋을 것 같다는 생각을 가지게 됐습니다.

opencv 알고리즘?

얼굴 인식해서 영역에서 제거하기 작업에서 사용?

Haar Cascades를 이용한 얼굴 검출 - haar 특징기반 다단계 분류자를 이용한 물체 검출로, 검출할 대상이 되는 물체가 있는 이미지와 없는 이미지를 (positive image, negative image) 최대한 많이 활용해서 다단계 함수를 훈련시키는 기계학습 방식이다.

http://dslab.konkuk.ac.kr/Class/2014/14CD2/16/%EC%A1%B8%EC%97%85%EC%9E%91%ED%92%88%20%EC%A4%91%EA%B0%84%EB%B3%B4%EA%B3%A0%EC%84%9C.pdf



